{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXbxOjPqDLva",
        "outputId": "777d71b1-0c19-48f1-a1e0-9d5c1b078751"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VRXk0Vu-H8u",
        "outputId": "35a6b2b9-310c-4756-c04c-a5362e7f77ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install sklearn\n",
        "!pip install nltk\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Download NLTK data for stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Import stopwords\n",
        "from nltk.corpus import stopwords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ESjf8ku-US5",
        "outputId": "b2e87c1a-318e-4ed2-ef9d-6d807f4877b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('/content/translated_train.csv')\n",
        "\n",
        "# Preprocess function\n",
        "def preprocess_text(text):\n",
        "    # Check if the text is a string before processing\n",
        "    if isinstance(text, str):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove punctuation\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "        # Remove numbers\n",
        "        text = re.sub(r'\\d+', '', text)\n",
        "        # Tokenize and remove stopwords\n",
        "        stop_words = set(stopwords.words('indonesian'))\n",
        "        words = word_tokenize(text)\n",
        "        text = ' '.join([word for word in words if word not in stop_words])\n",
        "        return text\n",
        "    else:\n",
        "        # Handle non-string values, e.g., by returning an empty string or NaN\n",
        "        return ''  # or pd.NA\n",
        "\n",
        "# Apply preprocessing to the context and response columns\n",
        "data['processed_context'] = data['translated_context'].apply(preprocess_text)\n",
        "data['processed_response'] = data['translated_response'].apply(preprocess_text)\n",
        "\n",
        "# Show the preprocessed data\n",
        "data[['translated_context', 'processed_context', 'translated_response', 'processed_response']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "sY5o2Etv-Zwf",
        "outputId": "8d9b368a-fd2f-484e-b0d6-493a76d1de41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  translated_context  \\\n",
              "0  Saya mengalami beberapa hal dengan perasaan da...   \n",
              "1  Saya mengalami beberapa hal dengan perasaan da...   \n",
              "2  Saya mengalami beberapa hal dengan perasaan da...   \n",
              "3  Saya mengalami beberapa hal dengan perasaan da...   \n",
              "4  Saya mengalami beberapa hal dengan perasaan da...   \n",
              "\n",
              "                                   processed_context  \\\n",
              "0  mengalami perasaan tidur memikirkan berharga m...   \n",
              "1  mengalami perasaan tidur memikirkan berharga m...   \n",
              "2  mengalami perasaan tidur memikirkan berharga m...   \n",
              "3  mengalami perasaan tidur memikirkan berharga m...   \n",
              "4  mengalami perasaan tidur memikirkan berharga m...   \n",
              "\n",
              "                                 translated_response  \\\n",
              "0  Jika semua orang berpikir Anda tidak berharga,...   \n",
              "1  Halo, dan terima kasih atas pertanyaan Anda da...   \n",
              "2  Hal pertama yang saya sarankan adalah mendapat...   \n",
              "3  Terapi sangat penting bagi mereka yang merasa ...   \n",
              "4  Pertama -tama saya ingin memberi tahu Anda bah...   \n",
              "\n",
              "                                  processed_response  \n",
              "0  orang berpikir berharga menemukan orang bergau...  \n",
              "1  halo terima kasih mencari nasihat perasaan ber...  \n",
              "2  sarankan tidur butuhkan memengaruhi berpikir m...  \n",
              "3  terapi depresi berharga mengalami kekhawatiran...  \n",
              "4  tama perasaan membantu mengubah perasaan mengu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36e1b341-b5a5-487a-9ace-dccdc754b037\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>translated_context</th>\n",
              "      <th>processed_context</th>\n",
              "      <th>translated_response</th>\n",
              "      <th>processed_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Saya mengalami beberapa hal dengan perasaan da...</td>\n",
              "      <td>mengalami perasaan tidur memikirkan berharga m...</td>\n",
              "      <td>Jika semua orang berpikir Anda tidak berharga,...</td>\n",
              "      <td>orang berpikir berharga menemukan orang bergau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Saya mengalami beberapa hal dengan perasaan da...</td>\n",
              "      <td>mengalami perasaan tidur memikirkan berharga m...</td>\n",
              "      <td>Halo, dan terima kasih atas pertanyaan Anda da...</td>\n",
              "      <td>halo terima kasih mencari nasihat perasaan ber...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Saya mengalami beberapa hal dengan perasaan da...</td>\n",
              "      <td>mengalami perasaan tidur memikirkan berharga m...</td>\n",
              "      <td>Hal pertama yang saya sarankan adalah mendapat...</td>\n",
              "      <td>sarankan tidur butuhkan memengaruhi berpikir m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Saya mengalami beberapa hal dengan perasaan da...</td>\n",
              "      <td>mengalami perasaan tidur memikirkan berharga m...</td>\n",
              "      <td>Terapi sangat penting bagi mereka yang merasa ...</td>\n",
              "      <td>terapi depresi berharga mengalami kekhawatiran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Saya mengalami beberapa hal dengan perasaan da...</td>\n",
              "      <td>mengalami perasaan tidur memikirkan berharga m...</td>\n",
              "      <td>Pertama -tama saya ingin memberi tahu Anda bah...</td>\n",
              "      <td>tama perasaan membantu mengubah perasaan mengu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36e1b341-b5a5-487a-9ace-dccdc754b037')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36e1b341-b5a5-487a-9ace-dccdc754b037 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36e1b341-b5a5-487a-9ace-dccdc754b037');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1fb1d303-63a8-4780-913d-4236c3e27db9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1fb1d303-63a8-4780-913d-4236c3e27db9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1fb1d303-63a8-4780-913d-4236c3e27db9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data[['translated_context', 'processed_context', 'translated_response', 'processed_response']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"translated_context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Saya mengalami beberapa hal dengan perasaan dan diri saya sendiri. Saya nyaris tidak tidur dan tidak melakukan apa -apa selain memikirkan bagaimana saya tidak berharga dan bagaimana saya seharusnya tidak berada di sini.\\n   Saya belum pernah mencoba atau merenungkan bunuh diri. Saya selalu ingin memperbaiki masalah saya, tetapi saya tidak pernah menyiasatinya.\\n   Bagaimana cara mengubah perasaan saya tidak berharga bagi semua orang?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"mengalami perasaan tidur memikirkan berharga mencoba merenungkan bunuh memperbaiki menyiasatinya mengubah perasaan berharga orang\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"translated_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Halo, dan terima kasih atas pertanyaan Anda dan mencari nasihat tentang ini. Perasaan tidak berharga adalah umum. Bahkan, kebanyakan orang, jika tidak semua, telah merasakan ini sampai taraf tertentu pada suatu saat dalam hidup mereka. Anda tidak sendirian.\\u00a0Mengubah perasaan kita seperti mengubah pikiran kita - sulit dilakukan. Pikiran kami sangat menakjubkan sehingga Anda mengubah pikiran Anda, yang lain bisa ada di sana untuk mengambil tempat. Tanpa izin Anda, pikiran lain bisa muncul di sana. Pikiran baru mungkin terasa lebih buruk dari yang terakhir! Dugaan saya adalah bahwa Anda telah mencoba beberapa hal untuk memperbaiki ini sendiri bahkan sebelum menjangkau di sini. Orang -orang sering mencoba memikirkan pikiran positif, berdebat dengan pikiran mereka, atau hanya mengatakan pada diri mereka sendiri bahwa mereka perlu \\\"keluar dari itu\\\" - yang juga merupakan pemikiran yang membawa beberapa kritik diri.\\u00a0Beberapa orang mencoba pendekatan yang berbeda, dan ada konselor di luar sana yang dapat membantu Anda dengan ini. Idenya adalah bahwa alih -alih mencoba mengubah pikiran, Anda mengubah cara Anda meresponsnya. Anda belajar keterampilan yang memungkinkan Anda untuk mengelola pikiran dan perasaan yang sulit secara berbeda sehingga mereka tidak memiliki dampak yang sama pada Anda yang mereka lakukan saat ini. Bagi sebagian orang, mereka benar -benar mulai mengalami pikiran yang kurang menyakitkan begitu mereka belajar bagaimana mengelola yang mereka miliki secara berbeda. Terapi penerimaan dan komitmen mungkin menjadi pilihan yang baik untuk Anda.\\u00a0Ada informasi online dan bahkan buku-buku swadaya yang dapat Anda gunakan untuk mengajari Anda keterampilan yang saya sebutkan. Karena mereka adalah keterampilan, mereka membutuhkan latihan, tetapi banyak orang telah menemukan kelegaan besar dan kehidupan yang diperkaya dengan mempelajarinya.\\u00a0Adapun pikiran bunuh diri, saya sangat senang membaca bahwa ini tidak terjadi pada Anda. Namun, Anda harus berhati -hati karena ini bisa menjadi tanda depresi yang memburuk. Jika Anda mulai memikirkan hal ini, penting untuk menjangkau sistem pendukung segera. Lifeline Pencegahan Bunuh Diri Nasional adalah 1-800-273-8255. Baris teks adalah #741741.\\u00a0Saya berharap beberapa kolega lain akan memberi Anda lebih banyak saran.\\u00a0Bersikaplah baik ... Robin Landwehr, DBH, LPCC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"halo terima kasih mencari nasihat perasaan berharga kebanyakan orang merasakan taraf hidup mengubah perasaan mengubah pikiran sulit pikiran menakjubkan mengubah pikiran mengambil izin pikiran muncul pikiran buruk dugaan mencoba memperbaiki menjangkau orang orang mencoba memikirkan pikiran positif berdebat pikiran pemikiran membawa kritik orang mencoba pendekatan berbeda konselor membantu idenya alih alih mencoba mengubah pikiran mengubah meresponsnya belajar keterampilan mengelola pikiran perasaan sulit berbeda memiliki dampak lakukan orang mengalami pikiran menyakitkan belajar mengelola miliki berbeda terapi penerimaan komitmen pilihan informasi online bukubuku swadaya mengajari keterampilan sebutkan keterampilan membutuhkan latihan orang menemukan kelegaan kehidupan diperkaya mempelajarinya pikiran bunuh senang membaca berhati hati tanda depresi memburuk memikirkan menjangkau sistem pendukung lifeline pencegahan bunuh nasional baris teks berharap kolega saran bersikaplah robin landwehr dbh lpcc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Assuming 'model', 'tokenizer', and 'device' (CPU or GPU) are already defined\n",
        "\n",
        "# Function to get batch embeddings\n",
        "def get_batch_embeddings(texts, batch_size=16):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "\n",
        "        # Tokenization and moving to the correct device (GPU/CPU)\n",
        "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Forward pass through the model\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        last_hidden = outputs.last_hidden_state\n",
        "        attention_mask = inputs['attention_mask']\n",
        "\n",
        "        # Apply mean pooling (sum and average over tokens)\n",
        "        mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n",
        "        summed = torch.sum(last_hidden * mask_expanded, 1)\n",
        "        counts = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "        mean_pooled = summed / counts\n",
        "\n",
        "        embeddings.append(mean_pooled.cpu().numpy())\n",
        "\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "# Function to get a single query embedding\n",
        "def get_query_embedding(query):\n",
        "    preprocessed = preprocess_text_indonesian(query)  # Preprocessing function for Indonesian text\n",
        "    inputs = tokenizer(preprocessed, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Forward pass through the model\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    last_hidden = outputs.last_hidden_state\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    # Apply mean pooling\n",
        "    mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n",
        "    summed = torch.sum(last_hidden * mask_expanded, 1)\n",
        "    counts = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "    mean_pooled = summed / counts\n",
        "\n",
        "    # Return as 2D array for compatibility with cosine similarity\n",
        "    return mean_pooled.cpu().numpy().reshape(1, -1)\n",
        "\n",
        "# Function to get semantic response from the chatbot\n",
        "def get_semantic_chatbot_response_with_fallback(user_query, df, context_embeddings, similarity_threshold=0.3):\n",
        "    # Preprocess query\n",
        "    preprocessed_query = preprocess_text_indonesian(user_query)\n",
        "    print(f\"Query pengguna setelah pra-pemrosesan: '{preprocessed_query}'\")\n",
        "\n",
        "    if not preprocessed_query.strip():\n",
        "        return \"Maaf, pertanyaan Anda kosong atau tidak dapat dipahami.\"\n",
        "\n",
        "    # Get the query embedding\n",
        "    embedding = get_query_embedding(preprocessed_query)\n",
        "\n",
        "    # Compute cosine similarity between query embedding and context embeddings\n",
        "    similarity_scores = cosine_similarity(embedding, context_embeddings)[0]\n",
        "    max_score = np.max(similarity_scores)\n",
        "    print(f\"Skor kemiripan tertinggi: {max_score:.4f}\")\n",
        "\n",
        "    # If similarity is below threshold, return fallback response\n",
        "    if max_score < similarity_threshold:\n",
        "        print(f\"Skor kemiripan ({max_score:.4f}) < threshold ({similarity_threshold})\")\n",
        "        return \"Maaf, saya belum memahami pertanyaan Anda dengan baik. Bisa dijelaskan dengan cara lain?\"\n",
        "\n",
        "    # Find the best matching response\n",
        "    best_idx = np.argmax(similarity_scores)\n",
        "    response_col = 'translated_response'\n",
        "\n",
        "    try:\n",
        "        # Get the response text from the best matching context\n",
        "        response_text = df.iloc[best_idx][response_col]\n",
        "        print(f\"Indeks respons terbaik: {best_idx}\")\n",
        "        print(f\"Respons yang ditemukan: {response_text}\")\n",
        "\n",
        "        # Ensure the response is valid (not empty or non-string)\n",
        "        if not isinstance(response_text, str) or not response_text.strip():\n",
        "            return \"Maaf, saya tidak menemukan jawaban yang sesuai.\"\n",
        "        return response_text\n",
        "    except KeyError:\n",
        "        return f\"Error: Kolom '{response_col}' tidak ditemukan.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Kesalahan saat mengambil respons: {e}\")\n",
        "        return \"Maaf, terjadi kesalahan teknis.\"\n"
      ],
      "metadata": {
        "id": "rqK9ARY3-kBx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare input-output pairs for the training\n",
        "input_texts = data['processed_context'].values\n",
        "target_texts = data['processed_response'].values\n",
        "\n",
        "# Define maximum length of the sequences (you can adjust this)\n",
        "MAX_SEQ_LENGTH = 50\n",
        "\n",
        "# Tokenize the input and output sequences\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(input_texts + target_texts)\n",
        "\n",
        "# Convert texts to sequences\n",
        "input_seq = tokenizer.texts_to_sequences(input_texts)\n",
        "target_seq = tokenizer.texts_to_sequences(target_texts)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=MAX_SEQ_LENGTH, padding='post')\n",
        "target_seq = tf.keras.preprocessing.sequence.pad_sequences(target_seq, maxlen=MAX_SEQ_LENGTH, padding='post')\n",
        "\n",
        "# Split into training and validation sets\n",
        "input_train, input_val, target_train, target_val = train_test_split(input_seq, target_seq, test_size=0.2)\n",
        "\n",
        "# Define model parameters\n",
        "input_dim = len(tokenizer.word_index) + 1\n",
        "output_dim = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 256\n",
        "hidden_units = 256\n",
        "\n",
        "# Build the encoder-decoder model using LSTM\n",
        "inputs = Input(shape=(MAX_SEQ_LENGTH,))\n",
        "x = Embedding(input_dim=input_dim, output_dim=embedding_dim)(inputs)\n",
        "x = LSTM(hidden_units, return_state=True)(x)\n",
        "encoder_outputs, state_h, state_c = x\n",
        "\n",
        "# Decoder part\n",
        "decoder_inputs = Input(shape=(MAX_SEQ_LENGTH,))\n",
        "x2 = Embedding(input_dim=input_dim, output_dim=embedding_dim)(decoder_inputs)\n",
        "x2 = LSTM(hidden_units, return_sequences=True)(x2, initial_state=[state_h, state_c])\n",
        "decoder_outputs = Dense(output_dim, activation='softmax')(x2)\n",
        "\n",
        "# Compile the model\n",
        "model = Model([inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "model.fit([input_train, target_train], target_train, batch_size=32, epochs=10, validation_data=([input_val, target_val], target_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtYZIhPbAeS6",
        "outputId": "03f7eaea-d6af-4671-c0de-ee1946e8f776"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.2032 - loss: 7.5709 - val_accuracy: 0.2190 - val_loss: 5.8106\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.2257 - loss: 5.6073 - val_accuracy: 0.2309 - val_loss: 5.3530\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.2430 - loss: 5.1987 - val_accuracy: 0.2571 - val_loss: 5.0546\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.2726 - loss: 4.8440 - val_accuracy: 0.3131 - val_loss: 4.6989\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.3366 - loss: 4.4786 - val_accuracy: 0.4545 - val_loss: 4.1714\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.4985 - loss: 3.8473 - val_accuracy: 0.5911 - val_loss: 3.4525\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.6268 - loss: 3.1205 - val_accuracy: 0.6916 - val_loss: 2.7751\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.7096 - loss: 2.4832 - val_accuracy: 0.7503 - val_loss: 2.2655\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.7754 - loss: 1.9209 - val_accuracy: 0.7985 - val_loss: 1.8967\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.8135 - loss: 1.6265 - val_accuracy: 0.8305 - val_loss: 1.6216\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x783acb30f3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}